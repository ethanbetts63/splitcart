Splitcart is a grocery price comparison application designed to help users find the best prices for their favorite products across different Australian grocery stores. To achieve this, it is crucial to accurately identify the same product even when it is listed with slight variations in different stores. This document outlines the entire data cleaning and de-duplication process, from raw data scraping to final database entry.

**Data Cleaning and De-duplication Pipeline**

The data pipeline has been redesigned into a simplified and more robust two-stage process: **Scraping** and **Database Updating**.

**Part 1: Scraping and Normalization**

1.  **Scrape Raw Data:** The process begins by scraping the raw product data directly from the grocery store's API using a management command (e.g., `python manage.py scrape --woolworths`).

2.  **Store-Specific Cleaning:** For each grocery store, a specialized cleaning function (e.g., `clean_raw_data_woolworths`) processes the raw JSON data. This function extracts and standardizes key information like name, brand, price, and category.

3.  **Centralized Normalization:** After the initial cleaning, a central utility, `normalize_product_data`, is applied to each product. This function performs several key tasks:
    *   **Size Extraction:** It intelligently extracts size information (e.g., "500g", "1L") from the product's name, brand, and size fields.
    *   **Name Cleaning:** It cleans the product name by removing redundant information that has already been extracted, such as brand and size.
    *   **De-duplication Key Generation:** It creates a `normalized_name_brand_size` key by combining the cleaned name, brand, and extracted sizes. This key is crucial for accurately identifying duplicate products.

4.  **Save to Product Inbox:** Instead of being saved in large batches, each cleaned and normalized product is saved as a separate JSON file in the `api/data/product_inbox/` directory. This isolates products and prevents an error with one product from affecting others.

**Part 2: Database Update and De-duplication**

1.  **Run Update Command:** The `update_db --products` management command initiates the database update process.

2.  **Consolidate from Inbox:** The command reads all the individual product JSON files from the `product_inbox`.

3.  **In-Memory De-duplication:** The script uses the `normalized_name_brand_size` key from each product file to perform an in-memory de-duplication. If multiple files share the same key, only the most recent one is kept, ensuring that the most up-to-date product information is used.

4.  **Batch Database Operations:** Once the unique products have been identified, the script performs the following actions in efficient batches:
    *   **Identify New Products:** It uses a tiered matching system (checking barcode, then store-specific ID, then the normalized string) to determine which products are genuinely new.
    *   **Create New Products:** It creates all new `Product` records in a single database transaction.
    *   **Create Prices:** It creates `Price` records for all products, linking them to the correct store and recording the current price.
    *   **Create Category Relationships:** It creates the necessary category relationships for the products.

5.  **Clean Up Inbox:** After a product's data has been successfully committed to the database, its corresponding file in the `product_inbox` is deleted.

**Key Benefits of the New Architecture:**

*   **Simplified Pipeline:** The elimination of the `process_raw_data` command and the intermediate `processed_data` directory makes the data flow easier to understand and maintain.
*   **Improved Accuracy:** The use of the more sophisticated `normalized_name_brand_size` key for de-duplication leads to more accurate product matching.
*   **Increased Resilience:** Saving each product to a separate file means that an error in one file will not halt the entire process.
*   **Maintained Performance:** The use of in-memory de-duplication and batch database operations ensures that the update process remains fast and efficient.