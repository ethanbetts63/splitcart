This document outlines the plan to implement a robust data reconciliation and name variation system. The goal is to solve two core problems: 1) The "Timing Gap", where product name variations are discovered after the de-duplication key has been generated, leading to temporary duplicates, and 2) The "Stale Data" problem, where long-running scrapers continue to use an outdated set of name variations. The solution is a multi-stage process that uses a "hotlist" file for immediate, cross-process communication of new discoveries, a "two-pass" cleanup system to merge duplicates after a database update, and a dynamic reloading mechanism for the scrapers.

1. product_name_translation_table.py is created at the end of the previous database update by reading the name variations field of every product in the database. 
2. the translation table is used to clean the product name used in the normalized name brand size string for each scraped product. 
3. database updating: works as per usual with two key changes. If it finds a product its adding exists in the database already but the names are different. It needs to additionally add the new name to the name variation field on the existing product. It also needs to add that information (name x is a variation of y) to a name_variation_hotlist.json file. 
4. now we continue as usual slowly growing our list of discovered names. We will accept here that some duplicates will get through because our normalized strings were created before the discovered names list. 
5. at the end of update_db we run a clean up function that looks at name_variation_hotlist and for each entry checks the database to see if a name variation has slipped through. It creates a list of these duplicates and then passes that two a deduplication util. 
6. lets call the primary existing product instance A and the new name variation duplicate B. The deduplication util will repoint all of B's price records at A. It will fill in any fields on A that A does not have but B does. 
7. Then finally we recreate the product_name_translation_table.py to make it current for the scrapers. 
**9. Implement Scraper Reload Mechanism**
   - The scraper runner scripts (e.g., `run_woolworths_scraper.py`) will be modified.
   - `import importlib` will be added to the top of the file.
   - The `product_name_translation_table` module will be imported.
   - Inside the main loop (e.g., after scraping each store or batch), a call to `importlib.reload()` will be added to refresh the translation table in memory.

---
### Relevant File Paths
---

**Files to be Created:**
- `C:\Users\ethan\coding\splitcart\api\data\product_name_translation_table.py` (autocreated by util)
- `C:\Users\ethan\coding\splitcart\api\data\name_variation_hotlist.json` (autocreated by util)
- `C:\Users\ethan\coding\splitcart\api\utils\database_updating_utils\merge_duplicate_products.py`
- `C:\Users\ethan\coding\splitcart\api\utils\database_updating_utils\create_update_product_name_translation_table.py
- `C:\Users\ethan\coding\splitcart\api\utils\database_updating_utils\create_update_name_variation_hotlist.py
- `C:\Users\ethan\coding\splitcart\api\utils\database_updating_utils\find_duplicate_name_variations.py
- 

files to be edited: 
- C:\Users\ethan\coding\splitcart\api\utils\database_updating_utils we are entirely working in here. 

